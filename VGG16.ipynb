{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "mount_file_id": "1xBYJ87yhNobdVvAIgN5oPid8KSOouIrw",
      "authorship_tag": "ABX9TyNHeAG8moKbCCvUe4HF47QM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varsha451srm/Assignment-1-Basic-Statistic_Level_1/blob/main/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y_3CoIYl05Wh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import  Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/CNN Multiclass/cnn task/train_data'\n",
        "valid_path = '/content/drive/MyDrive/CNN Multiclass/cnn task/test_data'"
      ],
      "metadata": {
        "id": "a2XC0l0M12az"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the VGG16 library as shown below and add preprocessing layer to the front of VGG\n",
        "# Here we will be using imagenet weights\n",
        "\n",
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q078i3Je2ILv",
        "outputId": "2f8a9696-994d-491f-b0b3-69b02d85daf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# don't train existing weights\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "X6W0C9cm3FQW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg16.output)"
      ],
      "metadata": {
        "id": "nhJw2iRo3z7E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=vgg16.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "RTLVZyyD4AAd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view the structure of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PonrvJEh4CfL",
        "outputId": "90741dbf-3a1f-452b-f696-6211c3b1c19d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 100356    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,815,044\n",
            "Trainable params: 100,356\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "BMquX7zx44ol"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ImageDataGenerator(horizontal_flip=True,vertical_flip=True, rescale=1./255)\n",
        "test_data  = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "Npko4Lw15WS7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_path = train_data.flow_from_directory(directory = '/content/drive/MyDrive/CNN Multiclass/cnn task/train_data',target_size=(224, 224))\n",
        "test_path     = test_data.flow_from_directory(directory='/content/drive/MyDrive/CNN Multiclass/cnn task/test_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMnXNHyv5nlA",
        "outputId": "fe47020e-d358-4ae9-b672-2048d8369306"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 164 images belonging to 4 classes.\n",
            "Found 37 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_path.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgMws3CU6CJ7",
        "outputId": "094cf388-9e77-4972-ea45-3b9daa638e44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mani': 0, 'manoj': 1, 'tasleem': 2, 'varsha': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_training = model.fit(x=training_path,batch_size=20,epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxehDt8v6GVY",
        "outputId": "2b08fbd4-f4c9-430c-9ef7-7279f498501f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6/6 [==============================] - 99s 13s/step - loss: 1.9365 - accuracy: 0.4817\n",
            "Epoch 2/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 1.0024 - accuracy: 0.7134\n",
            "Epoch 3/20\n",
            "6/6 [==============================] - 17s 3s/step - loss: 0.4839 - accuracy: 0.8293\n",
            "Epoch 4/20\n",
            "6/6 [==============================] - 16s 2s/step - loss: 0.5063 - accuracy: 0.8476\n",
            "Epoch 5/20\n",
            "6/6 [==============================] - 14s 3s/step - loss: 0.3219 - accuracy: 0.9024\n",
            "Epoch 6/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.2565 - accuracy: 0.9207\n",
            "Epoch 7/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.1705 - accuracy: 0.9451\n",
            "Epoch 8/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.1807 - accuracy: 0.9512\n",
            "Epoch 9/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0993 - accuracy: 0.9634\n",
            "Epoch 10/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0560 - accuracy: 0.9817\n",
            "Epoch 11/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0525 - accuracy: 0.9878\n",
            "Epoch 12/20\n",
            "6/6 [==============================] - 15s 2s/step - loss: 0.0379 - accuracy: 0.9878\n",
            "Epoch 13/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0250 - accuracy: 0.9939\n",
            "Epoch 14/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0265 - accuracy: 0.9878\n",
            "Epoch 15/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "6/6 [==============================] - 14s 3s/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "6/6 [==============================] - 14s 2s/step - loss: 0.0111 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('multiclass_intelligence.h5')"
      ],
      "metadata": {
        "id": "f7O7PBfA6pC8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/drive/MyDrive/CNN Multiclass/cnn task/test_data/varsha/IMG20211115162430.jpg', target_size = (224,224))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "# load model\n",
        "model = load_model('multiclass_intelligence.h5')\n",
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] == 1:\n",
        "    print('mani')\n",
        "   \n",
        "elif result[0][1] ==1:\n",
        "    print('manoj')\n",
        "    \n",
        "elif result[0][2]==1:\n",
        "    print(\"tasleem\")\n",
        "    \n",
        "else:\n",
        "    print(\"varsha\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQKV8qk67fYc",
        "outputId": "f4116575-d7bd-434e-f093-61e584117ae1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "varsha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/drive/MyDrive/CNN Multiclass/cnn task/test_data/mani/WhatsApp Image 2022-03-02 at 18.38.27.jpeg', target_size = (224,224))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "# load model\n",
        "model = load_model('multiclass_intelligence.h5')\n",
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] == 1:\n",
        "    print('mani')\n",
        "   \n",
        "elif result[0][1] ==1:\n",
        "    print('manoj')\n",
        "    \n",
        "elif result[0][2]==1:\n",
        "    print(\"tasleem\")\n",
        "    \n",
        "else:\n",
        "    print(\"varsha\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR_2KOAh9Mtl",
        "outputId": "473cff5e-8be6-4d98-83b1-302c9607a2c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f69600faf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "varsha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/drive/MyDrive/CNN Multiclass/cnn task/test_data/tasleem/WhatsApp Image 2022-03-02 at 21.00.28.jpeg', target_size = (224,224))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "# load model\n",
        "model = load_model('multiclass_intelligence.h5')\n",
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] == 1:\n",
        "    print('mani')\n",
        "   \n",
        "elif result[0][1] ==1:\n",
        "    print('manoj')\n",
        "    \n",
        "elif result[0][2]==1:\n",
        "    print(\"tasleem\")\n",
        "    \n",
        "elif result[0][3]==1:\n",
        "    print(\"varsha\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrXO-eIp971I",
        "outputId": "bbe2a391-050c-4383-f766-4db0d10b314b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "varsha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/drive/MyDrive/CNN Multiclass/cnn task/train_data/mani/WhatsApp Image 2022-03-02 at 18.27.08.jpeg', target_size = (224,224))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "# load model\n",
        "model = load_model('multiclass_intelligence.h5')\n",
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] == 1:\n",
        "    print('mani')\n",
        "   \n",
        "elif result[0][1] ==1:\n",
        "    print('manoj')\n",
        "    \n",
        "elif result[0][2]==1:\n",
        "    print(\"tasleem\")\n",
        "    \n",
        "elif result[0][3]==1:\n",
        "    print(\"varsha\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2-Z34JP-Vhy",
        "outputId": "33439fac-2d97-4a00-f8ae-2db68212f69d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f68eaff34d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "mani\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NzcMjm_0-5p1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}